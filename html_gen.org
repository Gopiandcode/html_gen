* HtmlGen
A simple little static templating engine for HTML.
Coded using literate programming.


* Preamble
While the overall nature of this project is quite simple - just a bit of file loading and exports, we can leverage rust's ecosystem to make our development a little easier.

** Crates
The crates we'll be using are as follows:
- *ArgParse* - This is a crate that I used a while back when making another command line application. It provides a very nice rustic interface over a library which produces command line interfaces compliant with most unix/linux standards.

#+begin_src rust :tangle src/main.rs  :comments org
extern crate argparse;
#+end_src

** Standard Library Imports
We'll be using the path utilities provided by the standard library to help us navigate the filesystem in a cross platform way.
#+begin_src rust :tangle src/main.rs :comments org
use std::path;
#+end_src
** Module structure
We'll be splitting up our codebase as follows:

#+begin_src rust :tangle src/main.rs :noweb yes :comments org
<<modules>>
#+end_src


* Command Line Interface
Clearly this project is going to be a command line application, as the static generator will need to parse a document and construct the components.

Using argparse - as imported in the preamble, we'll design a sweet and sexy interface to access our application. The main actions we'll allow a user to perform using this application will be as follows:
- *specify output folder* - by default the output of the compiled files are placed in ~./bin/~ dir, which is made if it does not exist.
- *specify template folder* - within a non-templated file, when a template reference is used, by default the application searches the 
 ~./template/~ dir to resolve these references.
- *specify input folder* - by default the program searches ~./src/~ for the source files to be compiled

#+begin_src rust :tangle src/main.rs :comments org :noweb yes
fn main() {
 <<high level interface>>
}
#+end_src
Now, as specified, our output and template paths take default values from where the application was instantiated.
#+name: high level interface
#+begin_src rust :comments org
    let mut output_path = String::from("./bin");
    let mut template_path = String::from("./template");
    let mut input_path = String::from("./src");
#+end_src


Using argparse, we can implement this cmdline interface as follows:
#+name: high level interface
#+begin_src rust :comments org
    {
        let mut ap = argparse::ArgumentParser::new();
        ap.set_description("Simple templating engine for html documents");
        ap.refer(&mut output_path)
        .add_option(&["-o","--output"], 
                    argparse::Store, 
                    "directory for the output files to be saved");

        ap.refer(&mut template_path)
        .add_option(&["-t","--template"], 
                    argparse::Store, 
                    "directory to be searched to find templates");

        ap.refer(&mut input_path)
        .add_option(&["-i","--input"], 
                    argparse::Store, "
                    directory in which the source files to be compiled are located");


        ap.parse_args_or_exit();
    }
#+end_src

* Core Logic
Now we've obtained the directory for the files to be stored, we can move on to the main logic of the program.
Fundamentaly the logic of this program can be split into two main components:
 - Recursively descending the source directory, keeping track of the file structure.
#+name: modules 
#+begin_src rust
mod parser;
#+end_src
 - Extracting the data from a given file
#+name: modules 
#+begin_src rust 
mod crawler;
#+end_src
 - generate a compiled html file from the template and save it to a folder
#+name: modules
#+begin_src rust
mod generator;
#+end_src 

Thus the high level execution of the system is as follows:
#+name: high level interface
#+begin_src rust :comments org
parser::parse_source_string("  \n#+template: simple\nbody: Kiran is the best \\¬ ¬");
#+end_src


** Parser Logic
Before we begin, we'll need the following packages in our parser:
#+begin_src rust :tangle src/parser.rs :noweb yes :comments org
use std::collections::HashMap;
<<structures>>
#+end_src
Once again, our core specification for the parser is to extract a set of key value pairs. Our syntax will be of the following form:
#+begin_src 
ID := (Sigma/{:, (, )})+
INTRO := #+template: Sigma+\n
MAPPING := ID:  ((SIGMA/{¬})|\¬)* ¬
DOCUMENT := INTRO MAPPING*
#+end_src
Our parser will take in a string (the contents of the file), and return either a hashmap of values and a template name, or an error.
#+begin_src rust :tangle src/parser.rs :noweb yes :comments org
pub fn parse_source_string(source: &str) 
   -> Result<(String, HashMap<String,String>),ParseError> {
<<source parsing utility functions>>
<<source parsing code>>
}

#[cfg(test)]
mod test {
   use super::*;

  <<source parsing tests>>
}
#+end_src
Where a parsing error will be one of the following:
 - **Template not found** - if the source file does not specify a template to be loaded
 - **Invalid identifier** - if an identifier contains an invalid character.
#+name: structures
#+begin_src rust :comments org
pub enum ParseError {
   TemplateNotFound,
   InvalidIdentifier
}
#+end_src
For simplicity, we're making the parser as general as possible and opting to make failure as unlikely as possible.

To do the parsing, first we start off by consuming the template directive, and failing if not present.

First, we check that the template contains a template directive - we're leaving resolving the template to a file to a later point.
#+name: source parsing code
#+begin_src rust :comments org
if !source.trim_left().starts_with("#+template:") {
   return Err(ParseError::TemplateNotFound);
}
#+end_src

This means that if a source does not start with a directive, its parsing will fail:
#+name: source parsing tests
#+begin_src rust :comments org
#[test]
fn must_start_with_template_directive() {
   assert!(parse_source_string("temp-justkidding\n id:\n #+template:\n").is_err());
}
#+end_src

After this check, we can safetly consume the first part of the string.
#+name: source parsing code
#+begin_src rust  :comments org
let source = source.trim_left().split_at(11).1;
#+end_src

Next, let's retrieve the actual template name - failing if it was not provided.
#+name: source parsing code
#+begin_src rust :comments org
let (raw_template_name, remaining_string) = split_at_pattern(source, "\n");
let template_name = raw_template_name.trim();
if template_name.is_empty() {
   return Err(ParseError::TemplateNotFound);
}
#+end_src

This also means that if a source does not provide a template name its parsing will fail:
#+name: source parsing tests
#+begin_src rust :comments org
#[test]
fn must_provide_template_name() {
    assert!(parse_source_string("#+template: example\n").is_ok());
    assert!(parse_source_string("#+template:\n").is_err());
    assert!(parse_source_string("#+template:    \n").is_err());
    assert!(parse_source_string("#+template:   \n  \n").is_err());
    assert!(parse_source_string("#+template:   \t  \n").is_err());
}
#+end_src


Now, our remaining task is to simply iterate through the remaining ~ID: DATA~ pairs, and accumulate these values into a hashmap - let's begin
by setting up an initial hashmap to store the files.
#+name: source_parsing code
#+begin_src rust :comments org
let data : Hashmap<String, String> = HashMap::new();
#+end_src

#+name: source parsing code
#+begin_src rust  :comments org
return Err(ParseError::TemplateNotFound);
#+end_src
Notice, that during the parsing, we're using our own custom function to allow us to split by a pattern, a feature the
stdlib doesn't seem to provide.

This utility function splits a string by the first occurance of a pattern returning a string up to the first occurrance 
of the pattern and a string continuing from the pattern - the second string contains the text matching the pattern.
#+name: source parsing utility functions
#+begin_src rust :comments org
fn split_at_pattern<'a>(string: &'a str, pat: &str) -> (&'a str, &'a str) {
  if let Some(ind) = string.find(pat) {
     string.split_at(ind)
  } else {
     (&"", string)
  }
}
#+end_src

** Crawler Logic
The core logic for the crawler is to descend the input directory, keeping track of the current path, pass each file through the parser, then pass on the generated mapping to the generator, along with a corresponding template file and output file.

#+begin_src rust :tangle src/crawler.rs :noweb yes :comments org
#+end_src


** Generator Logic

#+begin_src rust :tangle src/generator.rs :noweb yes :comments org
#+end_src

